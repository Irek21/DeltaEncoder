{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1466,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchLoader():\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.reference_features = self.random_pairs(features, labels)\n",
    "        self.labels = labels\n",
    "        \n",
    "    def random_pairs(self, X, labels):\n",
    "        Y = X.copy()\n",
    "        for l in range(labels.shape[1]):\n",
    "            inds = np.where(labels[:, l])[0]\n",
    "            inds_pairs = np.random.permutation(inds)\n",
    "            Y[inds, :] = X[inds_pairs, :]\n",
    "        return Y\n",
    "    \n",
    "    def batch_load(self, start, end):\n",
    "        if start == 0:\n",
    "            idx = np.r_[:self.features.shape[0]]\n",
    "            np.random.shuffle(idx)\n",
    "            self.features = self.features[idx]\n",
    "            self.reference_features = self.reference_features[idx]\n",
    "            self.labels = self.labels[idx]\n",
    "            \n",
    "        if end > self.features.shape[0]:\n",
    "            end = self.features.shape[0]\n",
    "            \n",
    "        return self.features[start:end], self.reference_features[start:end], self.labels[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_train = np.load('Data/DEdata/features_train.npy').astype('float32')\n",
    "# labels_train = np.load('Data/DEdata/labels_train.npy').astype('float32')\n",
    "loader = BatchLoader(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = np.zeros((80, 600, 2048), dtype=np.float32)\n",
    "for i in range(80):\n",
    "    with open('Data/PickledClasses/' + str(i), 'rb') as f:\n",
    "        data = pkl.load(f)\n",
    "    features_train[i] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Data/DEdata/features_train.npy', features_train.reshape(-1, 2048))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1359,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeltaEncoder(nn.Module):\n",
    "    def __init__(self, input_size=2048, hidden_size=8192, neck_size=16):\n",
    "        encoder = nn.Sequential(\n",
    "            nn.Linear(input_size * 2, hidden_size),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(hidden_size, neck_size),\n",
    "        )\n",
    "        \n",
    "        decoder = nn.Sequential(\n",
    "            nn.Linear(input_size + neck_size, hidden_size),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(hidden_size, input_size),\n",
    "        )\n",
    "        dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        super(DeltaEncoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, X1, X2):\n",
    "        out = self.dropout(X1)\n",
    "        out = torch.cat((out, X2), dim=1)\n",
    "        out = self.encoder(out)\n",
    "        \n",
    "        out = torch.cat((X2, out), dim=1)\n",
    "        out = self.decoder(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1406,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = DeltaEncoder(2048, 512, 8).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta-learning phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1407,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE = nn.L1Loss(reduction='none')\n",
    "MSE = nn.MSELoss(reduction='none')\n",
    "def weighted_MAE(predict, target):\n",
    "    batch_size = predict.shape[0]\n",
    "    feature_size = predict.shape[1]\n",
    "\n",
    "    substract_norm = MSE(predict, target)\n",
    "    L2_norms = torch.sum(substract_norm, dim=1) + 10e-7\n",
    "    weights = substract_norm / L2_norms.reshape((batch_size, 1)).expand((batch_size, feature_size))\n",
    "\n",
    "    substract = MAE(predict, target)\n",
    "    losses = torch.sum(substract * weights, dim=1)\n",
    "    loss = torch.mean(losses)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(G.parameters(), lr=10e-5)\n",
    "optimizer = torch.optim.Adam(G.parameters(), lr=10e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1418,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss 3.8619093894958496\n",
      "Epoch 0 Loss 3.8883285522460938\n",
      "Epoch 0 Loss 3.8175785541534424\n",
      "Epoch 0 Loss 3.8877413272857666\n",
      "Epoch 0 Loss 3.918534278869629\n",
      "Epoch 0 Loss 3.9437286853790283\n",
      "Epoch 0 Loss 3.9527225494384766\n",
      "Epoch 0 Loss 3.923792600631714\n",
      "Epoch 0 Loss 3.873991012573242\n",
      "Epoch 0 Loss 3.881967544555664\n",
      "Epoch 1 Loss 3.905362606048584\n",
      "Epoch 1 Loss 3.903092861175537\n",
      "Epoch 1 Loss 3.920227289199829\n",
      "Epoch 1 Loss 3.8377187252044678\n",
      "Epoch 1 Loss 3.878110885620117\n",
      "Epoch 1 Loss 3.9147236347198486\n",
      "Epoch 1 Loss 3.88032603263855\n",
      "Epoch 1 Loss 3.8578286170959473\n",
      "Epoch 1 Loss 3.87811541557312\n",
      "Epoch 1 Loss 3.854017734527588\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "train_size = 48000\n",
    "\n",
    "for epoch in range(2):\n",
    "    for i in range(train_size // batch_size):\n",
    "        features, reference_features, labels = loader.batch_load(i * batch_size, (i + 1) * batch_size)\n",
    "        features = torch.tensor(features, device=device, dtype=torch.float32, requires_grad=False)\n",
    "        reference_features = torch.tensor(reference_features, device=device, dtype=torch.float32, requires_grad=False)\n",
    "        predict = G(features, reference_features)\n",
    "        \n",
    "        loss = weighted_MAE(predict, features)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i % 10 == 0):\n",
    "            print('Epoch {} Loss {}'.format(epoch, loss.detach()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation & storing new samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1419,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeltaEncoderGenerator(nn.Module):\n",
    "    def __init__(self, input_size=2048, hidden_size=8192, neck_size=16):\n",
    "        encoder = nn.Sequential(\n",
    "            nn.Linear(input_size * 2, hidden_size),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(hidden_size, neck_size),\n",
    "        )\n",
    "        \n",
    "        decoder = nn.Sequential(\n",
    "            nn.Linear(input_size + neck_size, hidden_size),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(hidden_size, input_size),\n",
    "        )\n",
    "        dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        super(DeltaEncoderGenerator, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, X1, X2, shot):\n",
    "        out = self.dropout(X1)\n",
    "        out = torch.cat((out, X2), dim=1)\n",
    "        out = self.encoder(out)\n",
    "        \n",
    "        out = torch.cat((shot, out), dim=1)\n",
    "        out = self.decoder(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_trained = DeltaEncoderGenerator(2048, 512, 8).to(device)\n",
    "G_trained.load_state_dict(G.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 1, 2048])"
      ]
     },
     "execution_count": 1468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_shots = 1\n",
    "episode = torch.zeros(1, 5, num_shots, 2048, device=device, requires_grad=False)\n",
    "\n",
    "for i in range(5):\n",
    "    with open('Data/PickledClasses/' + str(95 + i), 'rb') as f:\n",
    "        data = pkl.load(f)\n",
    "        \n",
    "    shot_numbers = np.random.randint(0, 600, size=num_shots)\n",
    "    episode[0][i][:num_shots] = data[shot_numbers]\n",
    "    \n",
    "episode.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1469,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 processed.\n",
      "Class 1 processed.\n",
      "Class 2 processed.\n",
      "Class 3 processed.\n",
      "Class 4 processed.\n"
     ]
    }
   ],
   "source": [
    "# store samples to cpu!\n",
    "\n",
    "batch_size = 128\n",
    "gen_size = 1024\n",
    "train_size = 48000\n",
    "class_data = torch.zeros(gen_size, 2048, device=device, dtype=torch.float32, requires_grad=False)\n",
    "\n",
    "for class_num in range(5):\n",
    "    indices = np.random.randint(low=0, high=train_size // batch_size, size=gen_size // batch_size)\n",
    "    j = 0\n",
    "    for i in indices:\n",
    "        features, reference_features, labels = loader.batch_load(i * batch_size, (i + 1) * batch_size)\n",
    "        features = torch.tensor(features, device=device, dtype=torch.float32, requires_grad=False)\n",
    "        reference_features = torch.tensor(reference_features, device=device, dtype=torch.float32, requires_grad=False)\n",
    "        \n",
    "        shot = episode[0][class_num].expand(batch_size, 2048)\n",
    "        class_data[j * batch_size:(j + 1) * batch_size] = G_trained(features, reference_features, shot).detach()\n",
    "        j += 1\n",
    "        \n",
    "    with open('Data/DEFeatures/' + str(class_num), 'wb') as f:\n",
    "        pkl.dump(class_data, f)\n",
    "    print('Class {} processed.'.format(class_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package processed.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "class_size = 1024\n",
    "train_size = 48000\n",
    "pack_features = np.zeros((5, 2, 1024, 2048), dtype=np.float32)\n",
    "\n",
    "total_indices = np.random.permutation(train_size // batch_size)\n",
    "for class_num in range(5):\n",
    "    indices = total_indices[class_num * (class_size // batch_size):(class_num + 1) * (class_size // batch_size)]\n",
    "    j = 0\n",
    "    for i in indices:\n",
    "        features, reference_features, labels = loader.batch_load(i * batch_size, (i + 1) * batch_size)\n",
    "        pack_features[class_num][0][j * batch_size:(j + 1) * batch_size] = features\n",
    "        pack_features[class_num][1][j * batch_size:(j + 1) * batch_size] = reference_features\n",
    "        j += 1\n",
    "        \n",
    "with open('Data/SynthMaterial/0', 'wb') as f:\n",
    "    pkl.dump({'features': pack_features}, f)\n",
    "print('Package processed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2, 1024, 2048)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pack_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training target classyfier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1470,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchLoader():\n",
    "    def __init__(self, class_size, num_classes, first_class, batch_size, batches_in_buff, path):\n",
    "        self.class_size = class_size\n",
    "        self.num_classes = num_classes\n",
    "        self.first_class = first_class\n",
    "        self.batch_size = batch_size\n",
    "        self.batches_in_buff = batches_in_buff\n",
    "        self.path = path\n",
    "        \n",
    "        self.indices = np.random.permutation(num_classes * class_size)\n",
    "        self.buff_size = batches_in_buff * batch_size\n",
    "        self.buff = [{'label': 0, 'features': torch.zeros(2048, device=device)} for i in range(self.buff_size)]\n",
    "        self.buff_num = 0\n",
    "    \n",
    "    def buff_gen(self, buff_num):\n",
    "        buff_indices = self.indices[buff_num * self.buff_size:(buff_num + 1) * self.buff_size]\n",
    "\n",
    "        for i in range(self.num_classes):\n",
    "            with open(self.path + str(self.first_class + i), 'rb') as f:\n",
    "                class_data = pkl.load(f)\n",
    "\n",
    "            class_indices = np.where(((buff_indices < (i + 1) * self.class_size) & (buff_indices >= i * self.class_size)))[0]\n",
    "            for j in class_indices:\n",
    "                self.buff[j] = {\n",
    "                    'label': i,\n",
    "                    'features': class_data[buff_indices[j] % self.class_size]\n",
    "                }\n",
    "    \n",
    "    def batch_load(self, i):\n",
    "        buff_i = i % self.batches_in_buff\n",
    "        if (buff_i == 0):\n",
    "            self.buff_gen(self.buff_num)\n",
    "            self.buff_num += 1\n",
    "            \n",
    "        return self.buff[buff_i * self.batch_size:(buff_i + 1) * self.batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1471,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classyfier(nn.Module):\n",
    "    def __init__(self):\n",
    "        fc_layers = nn.Sequential(\n",
    "            nn.Linear(2048, 5),\n",
    "            # nn.Linear(512, 256),\n",
    "            # nn.Linear(256, 5),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        super(Classyfier, self).__init__()\n",
    "        self.fc = fc_layers\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1472,
   "metadata": {},
   "outputs": [],
   "source": [
    "classyfier = Classyfier().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(classyfier.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1473,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss = 1.2448004484176636\n",
      "Epoch 1 Loss = 1.2351857423782349\n",
      "Epoch 2 Loss = 1.1250107288360596\n"
     ]
    }
   ],
   "source": [
    "class_size = 1024 # + 21997\n",
    "num_classes = 5\n",
    "first_class = 0\n",
    "train_size = class_size * num_classes\n",
    "batch_size = 128\n",
    "batches_in_buff = 128\n",
    "buff_size = batch_size * batches_in_buff\n",
    "\n",
    "for epoch in range(3):\n",
    "    loader = BatchLoader(class_size, num_classes, first_class, batch_size, batches_in_buff, 'Data/DEFeatures/')\n",
    "    for i in range(train_size // batch_size):\n",
    "        batch_tuple = loader.batch_load(i)\n",
    "        images = torch.zeros(batch_size, 2048, device=device, requires_grad=False)\n",
    "        labels = torch.zeros(batch_size, device=device, requires_grad=False, dtype=int)\n",
    "        for k in range(batch_size):\n",
    "            images[k] = batch_tuple[k]['features']\n",
    "            labels[k] = batch_tuple[k]['label']\n",
    "        \n",
    "        predict = classyfier(images)\n",
    "        loss = criterion(predict, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_value = loss.detach()\n",
    "    \n",
    "    # if (epoch % 10 == 0):\n",
    "    print('Epoch {} Loss = {}'.format(epoch, loss_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on FSL task = 74 %\n"
     ]
    }
   ],
   "source": [
    "class_size = 600\n",
    "num_classes = 5\n",
    "first_class = 95\n",
    "train_size = class_size * 5\n",
    "batch_size = 100\n",
    "batches_in_buff = 10\n",
    "buff_size = batch_size * batches_in_buff\n",
    "loader = BatchLoader(class_size, num_classes, first_class, batch_size, batches_in_buff, 'Data/PickledClasses/')\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for i in range(train_size // batch_size):\n",
    "    batch_tuple = loader.batch_load(i)\n",
    "    images = torch.zeros(batch_size, 2048, device=device, requires_grad=False)\n",
    "    labels = torch.zeros(batch_size, device=device, requires_grad=False, dtype=int)\n",
    "    for k in range(batch_size):\n",
    "        images[k] = batch_tuple[k]['features']\n",
    "        labels[k] = batch_tuple[k]['label'] # don't forget about this\n",
    "        \n",
    "    predict = classyfier(images)\n",
    "    _, predicted = torch.max(predict.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print('Accuracy on FSL task = {} %'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeltaEncoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=512, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=8, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=2056, out_features=512, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 1465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(G.to('cpu').state_dict(), 'Models/G')\n",
    "G.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classyfier(\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (2): Linear(in_features=256, out_features=5, bias=True)\n",
       "    (3): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(classyfier.to('cpu').state_dict(), 'Models/classyfier')\n",
    "classyfier.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classyfier.load_state_dict(torch.load(\"Models/classyfier\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.load_state_dict(torch.load(\"Models/G\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 1, 2048])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode = torch.load('episode.pt')\n",
    "episode.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
